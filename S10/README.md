# Loss Graph
![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/Loss%20Graph.png?raw=true)


# Accuracy Graph
![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/Accuracy%20Graph.png?raw=true)


# GradCam for few Misclassiied Images
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam1.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam2.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam3.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam4.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam5.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam6.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam7.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam8.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam9.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam10.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam11.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam12.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam13.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam14.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam15.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam16.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam17.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam18.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam19.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam20.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam21.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam23.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam24.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam25.png?raw=true)
* ![alt text](https://github.com/fatsoengineer/Computer_Vision_Course/blob/master/S10/additional_files/GradCam26.png?raw=true)


# Final Test Accuracy 
>  91.51% 

> Total Epochs: 50

# Logs
```
  0%|          | 0/782 [00:00<?, ?it/s]EPOCH:1 | LR: 0.022908676527677727
Loss=2.0826728343963623 Batch_id=781 Accuracy=40.67: 100%|██████████| 782/782 [00:37<00:00, 20.91it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0203, Accuracy: 5352/10000 (53.52%)

EPOCH:2 | LR: 0.022908676527677727
Loss=1.6798973083496094 Batch_id=781 Accuracy=58.49: 100%|██████████| 782/782 [00:37<00:00, 20.97it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0163, Accuracy: 6474/10000 (64.74%)

EPOCH:3 | LR: 0.022908676527677727
Loss=0.5074613094329834 Batch_id=781 Accuracy=67.34: 100%|██████████| 782/782 [00:37<00:00, 20.93it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0110, Accuracy: 7533/10000 (75.33%)

EPOCH:4 | LR: 0.022908676527677727
Loss=0.9529299139976501 Batch_id=781 Accuracy=71.88: 100%|██████████| 782/782 [00:37<00:00, 20.94it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0112, Accuracy: 7514/10000 (75.14%)

EPOCH:5 | LR: 0.022908676527677727
Loss=0.7231287360191345 Batch_id=781 Accuracy=75.27: 100%|██████████| 782/782 [00:37<00:00, 20.92it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0105, Accuracy: 7735/10000 (77.35%)

EPOCH:6 | LR: 0.022908676527677727
Loss=1.1850215196609497 Batch_id=781 Accuracy=77.74: 100%|██████████| 782/782 [00:37<00:00, 20.91it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0089, Accuracy: 8112/10000 (81.12%)

EPOCH:7 | LR: 0.022908676527677727
Loss=0.8584098815917969 Batch_id=781 Accuracy=79.34: 100%|██████████| 782/782 [00:37<00:00, 21.02it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0093, Accuracy: 8066/10000 (80.66%)

EPOCH:8 | LR: 0.022908676527677727
Loss=0.3899223208427429 Batch_id=781 Accuracy=80.71: 100%|██████████| 782/782 [00:37<00:00, 21.05it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0076, Accuracy: 8337/10000 (83.37%)

EPOCH:9 | LR: 0.022908676527677727
Loss=0.4872395098209381 Batch_id=781 Accuracy=82.11: 100%|██████████| 782/782 [00:37<00:00, 21.07it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0080, Accuracy: 8335/10000 (83.35%)

EPOCH:10 | LR: 0.022908676527677727
Loss=0.7855402231216431 Batch_id=781 Accuracy=83.17: 100%|██████████| 782/782 [00:37<00:00, 21.09it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0069, Accuracy: 8532/10000 (85.32%)

EPOCH:11 | LR: 0.022908676527677727
Loss=0.2323262095451355 Batch_id=781 Accuracy=84.28: 100%|██████████| 782/782 [00:36<00:00, 21.15it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0072, Accuracy: 8516/10000 (85.16%)

EPOCH:12 | LR: 0.022908676527677727
Loss=0.3354554772377014 Batch_id=781 Accuracy=85.13: 100%|██████████| 782/782 [00:37<00:00, 20.97it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0062, Accuracy: 8684/10000 (86.84%)

EPOCH:13 | LR: 0.022908676527677727
Loss=0.8152070045471191 Batch_id=781 Accuracy=85.98: 100%|██████████| 782/782 [00:36<00:00, 21.14it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0067, Accuracy: 8570/10000 (85.70%)

EPOCH:14 | LR: 0.022908676527677727
Loss=0.3233632743358612 Batch_id=781 Accuracy=86.78: 100%|██████████| 782/782 [00:36<00:00, 21.16it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0066, Accuracy: 8626/10000 (86.26%)

EPOCH:15 | LR: 0.022908676527677727
Loss=0.6727626323699951 Batch_id=781 Accuracy=87.50: 100%|██████████| 782/782 [00:36<00:00, 21.14it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0061, Accuracy: 8719/10000 (87.19%)

EPOCH:16 | LR: 0.022908676527677727
Loss=0.2977197766304016 Batch_id=781 Accuracy=87.94: 100%|██████████| 782/782 [00:36<00:00, 21.18it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0064, Accuracy: 8675/10000 (86.75%)

EPOCH:17 | LR: 0.022908676527677727
Loss=0.09374436736106873 Batch_id=781 Accuracy=88.75: 100%|██████████| 782/782 [00:36<00:00, 21.16it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0063, Accuracy: 8775/10000 (87.75%)

EPOCH:18 | LR: 0.022908676527677727
Loss=0.4861196279525757 Batch_id=781 Accuracy=89.17: 100%|██████████| 782/782 [00:36<00:00, 21.20it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0058, Accuracy: 8823/10000 (88.23%)

EPOCH:19 | LR: 0.022908676527677727
Loss=0.24860580265522003 Batch_id=781 Accuracy=89.65: 100%|██████████| 782/782 [00:37<00:00, 21.09it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0058, Accuracy: 8848/10000 (88.48%)

EPOCH:20 | LR: 0.022908676527677727
Loss=0.4826849102973938 Batch_id=781 Accuracy=90.18: 100%|██████████| 782/782 [00:36<00:00, 21.19it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0060, Accuracy: 8850/10000 (88.50%)

EPOCH:21 | LR: 0.022908676527677727
Loss=0.5620717406272888 Batch_id=781 Accuracy=90.59: 100%|██████████| 782/782 [00:36<00:00, 21.14it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0058, Accuracy: 8893/10000 (88.93%)

EPOCH:22 | LR: 0.022908676527677727
Loss=0.30951210856437683 Batch_id=781 Accuracy=90.78: 100%|██████████| 782/782 [00:36<00:00, 21.29it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0060, Accuracy: 8859/10000 (88.59%)

EPOCH:23 | LR: 0.022908676527677727
Loss=0.5046570897102356 Batch_id=781 Accuracy=91.36: 100%|██████████| 782/782 [00:36<00:00, 21.33it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0057, Accuracy: 8926/10000 (89.26%)

EPOCH:24 | LR: 0.022908676527677727
Loss=0.4078260362148285 Batch_id=781 Accuracy=91.66: 100%|██████████| 782/782 [00:36<00:00, 21.26it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0058, Accuracy: 8918/10000 (89.18%)

EPOCH:25 | LR: 0.022908676527677727
Loss=0.5394659638404846 Batch_id=781 Accuracy=91.99: 100%|██████████| 782/782 [00:36<00:00, 21.17it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0055, Accuracy: 8965/10000 (89.65%)

EPOCH:26 | LR: 0.022908676527677727
Loss=0.8356308937072754 Batch_id=781 Accuracy=92.22: 100%|██████████| 782/782 [00:36<00:00, 21.27it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0059, Accuracy: 8982/10000 (89.82%)

EPOCH:27 | LR: 0.022908676527677727
Loss=0.10350608825683594 Batch_id=781 Accuracy=92.62: 100%|██████████| 782/782 [00:37<00:00, 21.12it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0061, Accuracy: 8906/10000 (89.06%)

EPOCH:28 | LR: 0.022908676527677727
Loss=0.08336997032165527 Batch_id=781 Accuracy=92.77: 100%|██████████| 782/782 [00:36<00:00, 21.30it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0060, Accuracy: 8941/10000 (89.41%)

EPOCH:29 | LR: 0.022908676527677727
Loss=0.6014174818992615 Batch_id=781 Accuracy=93.24: 100%|██████████| 782/782 [00:36<00:00, 21.20it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0060, Accuracy: 8933/10000 (89.33%)

EPOCH:30 | LR: 0.022908676527677727
Loss=0.09062978625297546 Batch_id=781 Accuracy=93.22: 100%|██████████| 782/782 [00:36<00:00, 21.21it/s]
  0%|          | 0/782 [00:00<?, ?it/s]Epoch    30: reducing learning rate of group 0 to 2.2909e-03.

Test set: Average loss: 0.0059, Accuracy: 8941/10000 (89.41%)

EPOCH:31 | LR: 0.002290867652767773
Loss=0.035924941301345825 Batch_id=781 Accuracy=95.15: 100%|██████████| 782/782 [00:36<00:00, 21.27it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0052, Accuracy: 9106/10000 (91.06%)

EPOCH:32 | LR: 0.002290867652767773
Loss=0.1640670895576477 Batch_id=781 Accuracy=95.66: 100%|██████████| 782/782 [00:36<00:00, 21.25it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0053, Accuracy: 9114/10000 (91.14%)

EPOCH:33 | LR: 0.002290867652767773
Loss=0.11328262090682983 Batch_id=781 Accuracy=96.00: 100%|██████████| 782/782 [00:36<00:00, 21.26it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0054, Accuracy: 9111/10000 (91.11%)

EPOCH:34 | LR: 0.002290867652767773
Loss=0.0482197105884552 Batch_id=781 Accuracy=96.16: 100%|██████████| 782/782 [00:36<00:00, 21.42it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0053, Accuracy: 9122/10000 (91.22%)

EPOCH:35 | LR: 0.002290867652767773
Loss=0.005793571472167969 Batch_id=781 Accuracy=96.16: 100%|██████████| 782/782 [00:37<00:00, 21.13it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0054, Accuracy: 9117/10000 (91.17%)

EPOCH:36 | LR: 0.002290867652767773
Loss=0.28072527050971985 Batch_id=781 Accuracy=96.32: 100%|██████████| 782/782 [00:37<00:00, 21.06it/s]
  0%|          | 0/782 [00:00<?, ?it/s]Epoch    36: reducing learning rate of group 0 to 2.2909e-04.

Test set: Average loss: 0.0053, Accuracy: 9136/10000 (91.36%)

EPOCH:37 | LR: 0.0002290867652767773
Loss=0.029839783906936646 Batch_id=781 Accuracy=96.45: 100%|██████████| 782/782 [00:37<00:00, 20.64it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0053, Accuracy: 9148/10000 (91.48%)

EPOCH:38 | LR: 0.0002290867652767773
Loss=0.7448521852493286 Batch_id=781 Accuracy=96.39: 100%|██████████| 782/782 [00:37<00:00, 20.97it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0053, Accuracy: 9128/10000 (91.28%)

EPOCH:39 | LR: 0.0002290867652767773
Loss=0.04281100630760193 Batch_id=781 Accuracy=96.51: 100%|██████████| 782/782 [00:37<00:00, 21.13it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0053, Accuracy: 9150/10000 (91.50%)

EPOCH:40 | LR: 0.0002290867652767773
Loss=0.19737952947616577 Batch_id=781 Accuracy=96.52: 100%|██████████| 782/782 [00:36<00:00, 21.19it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0054, Accuracy: 9143/10000 (91.43%)

EPOCH:41 | LR: 0.0002290867652767773
Loss=0.009212791919708252 Batch_id=781 Accuracy=96.53: 100%|██████████| 782/782 [00:36<00:00, 21.14it/s]
  0%|          | 0/782 [00:00<?, ?it/s]Epoch    41: reducing learning rate of group 0 to 1.0000e-04.

Test set: Average loss: 0.0052, Accuracy: 9154/10000 (91.54%)

EPOCH:42 | LR: 0.0001
Loss=0.021600306034088135 Batch_id=781 Accuracy=96.66: 100%|██████████| 782/782 [00:36<00:00, 21.26it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0053, Accuracy: 9150/10000 (91.50%)

EPOCH:43 | LR: 0.0001
Loss=0.30072319507598877 Batch_id=781 Accuracy=96.62: 100%|██████████| 782/782 [00:36<00:00, 21.14it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0054, Accuracy: 9141/10000 (91.41%)

EPOCH:44 | LR: 0.0001
Loss=0.03155699372291565 Batch_id=781 Accuracy=96.65: 100%|██████████| 782/782 [00:36<00:00, 21.18it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0053, Accuracy: 9142/10000 (91.42%)

EPOCH:45 | LR: 0.0001
Loss=0.24165022373199463 Batch_id=781 Accuracy=96.58: 100%|██████████| 782/782 [00:36<00:00, 21.26it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0053, Accuracy: 9139/10000 (91.39%)

EPOCH:46 | LR: 0.0001
Loss=0.00514337420463562 Batch_id=781 Accuracy=96.68: 100%|██████████| 782/782 [00:41<00:00, 19.02it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0053, Accuracy: 9161/10000 (91.61%)

EPOCH:47 | LR: 0.0001
Loss=0.0005754232406616211 Batch_id=781 Accuracy=96.71: 100%|██████████| 782/782 [00:37<00:00, 20.74it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0053, Accuracy: 9162/10000 (91.62%)

EPOCH:48 | LR: 0.0001
Loss=0.3669161796569824 Batch_id=781 Accuracy=96.73: 100%|██████████| 782/782 [00:37<00:00, 20.78it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0053, Accuracy: 9159/10000 (91.59%)

EPOCH:49 | LR: 0.0001
Loss=0.5193064212799072 Batch_id=781 Accuracy=96.58: 100%|██████████| 782/782 [00:37<00:00, 20.72it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.0054, Accuracy: 9152/10000 (91.52%)

EPOCH:50 | LR: 0.0001
Loss=0.10528433322906494 Batch_id=781 Accuracy=96.66: 100%|██████████| 782/782 [00:37<00:00, 20.71it/s]

Test set: Average loss: 0.0054, Accuracy: 9151/10000 (91.51%)
```